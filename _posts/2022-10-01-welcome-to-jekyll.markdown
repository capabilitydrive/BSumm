---
layout: post
title: "Think like Elon Musk!"
date: 2022-10-01 14:40:35 +1300
categories: jekyll update
---

**Notable Quotes**

> As the creation of the first general intelligence is less than 80 years away (based on the progress we have so far and its extrapolation in the future), we are faced with a difficult question: **how will we ensure that our creation will not destroy us.**

- Superintelligence, Nick Bostrom

> Your synapses store all your knowledge and skills as roughly 100 terabytesâ€™ worth of information, while your DNA stores merely about a gigabyte, barely enough to store a single movie download.

- Life 3.0, Max Tegmark

<br><br>
Elon has been quite outspoken regarding the steps mankind will need to put in place to prevent Artificial Intelligence inadvertly killing off mankind in the process.

All three of these latest book titles have been recommended by Elon himself, so they give you some idea where his mindset is at, and indeed he actually helped contribute to at least one of them. The three books are quite detailed and technical but read the summaries if you find this a problem.

<br><br><br>

# My review of all 3 books

| Book                                                                  | My Review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Book summaries                                                                                                                                       |
| --------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| <img src="/BSumm/imgs/superintelligence.jpg" alt="superintelligence"> | A thought provoking, but also at times i felt quite distopian view of what A.I. might become in the future. <br>An interesting point is that if humankind were to cybernetically enhance itself we effectively become the robots (the "AI") of the future. Would this be our best chance of survival?                                                                                                                                                                                                                                                                   | [medium article](https://medium.com/@rossrco/book-review-superintelligence-paths-dangers-strategies-by-nick-bostrom-19675475d31f){:target="\_blank"} |
| <img src="/BSumm//imgs/life 3.jpg" alt="life 3.0">                    | Max's references to Life 1.0, 2.0 and 3.0 as evolutions in intelligence, making the claim that Life 3.0 being the time time when we design our own software and hardware. I like the way Max likens humans to a kind of device as well - quoting the synapses in our brains store roughly 100 terrbytes of data (how much would that cost to produce by today's standards?)                                                                                                                                                                                             | [make me read](https://makemeread.in/life-3-0-book-summary/){:target="\_blank"}                                                                      |
| <img src="/BSumm//imgs/human compatible.jpg" alt="human compatible">  | Russell refers to the first (1950s), second (1980s) and third (now) rises in AI and how the first two "failed". Intelligence again is a common theme in this book with reference to the Turing Test (and how this used to be a measure of AI intelligence, but not any more). i like the way Russell does more to relate AI to the goals humans are trying to achieve, or jobs that may be replaced in the future for example. Additionally I like Stuart Russell's arguments he puts forwards - he discusses different AI future scenarios which I see and understand. | [Fanchen Bao](https://fanchenbao.medium.com/book-summary-of-human-compatible-6f36a8b89bf9){:target="\_blank"}                                        |

# My take-aways/thoughts

I think all three books really opened my eyes to many diffent possibilities with AI and all three explained it with a different approach to the subject. i do find it interesting that whenever future advancement or autonomy is written about in a bold way, writers always put timeframes to their future predictions. This, i imagine, is something they do because they are always asked this question shortly after their prediction "... so how long before you would expect this happen?"<br><br>In my opinion, IT/future predictions are inevitably bolder than the likely true timeframe. Think autonomous cars, we were being told how all vehicles would be completely autonmous by 2025 (something like that!) Even electric cars - we still cannot manufacture cheap and environmentally-friendily EV batteries yet. <br><br>So when I extrapolate these trends, predictions and bold claims to humans, I think about how humankind has not come even close to replicating a human being yet. Then I think, well you would design a robot in humankinds' image anyway, why would you? In my mind, robots are really good at a carrying out a narrow field of choices, operations, based upon a set of circumstances - think chess robots, war drones, robot chefs etc but they don't go off and make a cup of tea afterwards, go for a swim, have fun with their mates, decide they won't go out for 2 hours because the weather might change. I'm not saying they can't be programmed to do that, or learn to think adaptively etc but how far away is that? Humans have to deliver a SuperIntelligent robot in the first place, and in my admitted limited view/knowledge, I am not convinced that is going to happen anytime soon? One can only hope we've managed to move to alternative universes by then if we are going to continue to thrive for another millenia?
<br><br>

# My favourite

Human Compatible is my favourite I think because it tries to do more to make AI more human-relatable. Russell also makes some great arguments that are not just about the inevitable demise of the human race as a result of a SuperIntelligent robot race that we are unable to control. One of his arguments for example is that SuperIntelligent AI does not need to be smarter that humans to cause trouble. One thing is for sure - this debate is going to rage for a long time.
<br><br>
**Let me know what you think? Maybe I under-estimate the pace at which AI is being developed?**

Other Articles:
[summary](https://www.livescience.com/29379-intelligent-robots-will-overtake-humans.html){:target="\_blank"}
